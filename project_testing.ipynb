{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marcusflygar1-hash/project_testing/blob/main/project_testing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# OBS! README\n",
        "\n",
        "For clarification the GridSearch part of this project was created through ai of AI.\n",
        "\n",
        "Also be wary of what code you run in which order.\n",
        "If you want to see  the results while using PCA, DO NOT run the entire notebook at once, you have to pick and chose what parts you run. Same goes for all types of functions and especially if you want to garner the results from the supervised labeling that I have done my self."
      ],
      "metadata": {
        "id": "Fx6RkNTJs1n-"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zOlF-8LGq-4w"
      },
      "source": [
        "#  Setup & Imports"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "EVRBMDFEsWgL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yO-vUlw1yKh0"
      },
      "outputs": [],
      "source": [
        "# importing the neccesary libraries for the project.\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.metrics import auc,roc_auc_score,roc_curve, accuracy_score, confusion_matrix, mean_squared_error, mean_absolute_error, mean_absolute_percentage_error, mean_squared_log_error, r2_score, precision_score, recall_score, f1_score, classification_report\n",
        "from sklearn.model_selection import cross_val_score, GridSearchCV, KFold, RandomizedSearchCV, train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from xgboost import XGBRegressor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_BM5brUj9AIe"
      },
      "source": [
        "Nya features att addera:\n",
        "\n",
        "Veckodagar, mÃ¥nad & ?\n",
        "\n",
        "\n",
        "GÃ¶r modellen mer robust, genom att normalisera portal datan?\n",
        "\n",
        "GridSearchCV? ..\n",
        "FÃ¶r rapporten: hade video sensorer varit Ã¤nnu bÃ¤ttre fÃ¶r att se om det sker \"micro-congestions\" vid vissa tillfÃ¤llen, pÃ¥verkat av fÃ¶rare som tvÃ¤rbromsar, byter fil utan at blinka etc..\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xrrMgzygaK7k",
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "# PCA Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ip3jyh26X6Zv"
      },
      "outputs": [],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "def pca_anomaly_labeling(df, n_components=3, contamination=0.1):\n",
        "    \"\"\"\n",
        "    Unsupervised anomaly detection using PCA reconstruction error.\n",
        "    Marks high reconstruction errors (low speeds, unusual patterns) as congestion = 1.\n",
        "    \"\"\"\n",
        "    df = df.copy().dropna(subset=[\"SPEED_MS_AVG\", \"FLOW\"])\n",
        "    features = [\"SPEED_MS_AVG\", \"FLOW\"]\n",
        "\n",
        "    # Normalize before PCA\n",
        "    X = StandardScaler().fit_transform(df[features])\n",
        "\n",
        "    pca = PCA(n_components=n_components, random_state=42)\n",
        "    X_pca = pca.fit_transform(X)\n",
        "    X_reconstructed = pca.inverse_transform(X_pca)\n",
        "\n",
        "    # Compute reconstruction error\n",
        "    errors = np.mean((X - X_reconstructed) ** 2, axis=1)\n",
        "    df[\"pca_error\"] = errors\n",
        "\n",
        "    # Determine threshold based on contamination fraction (top X% anomalies)\n",
        "    threshold = np.percentile(errors, 100 * (1 - contamination))\n",
        "    df[\"pca_congestion\"] = (df[\"pca_error\"] > threshold).astype(int)\n",
        "\n",
        "    return df, threshold\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7RsN-zqHaNuX",
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "# Clustering Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WZO-mGIaaNcg"
      },
      "outputs": [],
      "source": [
        "from sklearn.cluster import KMeans\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "def kmeans_congestion_labeling(df, n_clusters=3):\n",
        "    \"\"\"\n",
        "    Unsupervised labeling using KMeans clustering on SPEED_MS_AVG and FLOW.\n",
        "    Assigns the cluster with the lowest mean speed as 'congested' (label=1).\n",
        "    \"\"\"\n",
        "    df = df.copy().dropna(subset=[\"SPEED_MS_AVG\", \"FLOW\"])\n",
        "    features = [\"SPEED_MS_AVG\", \"FLOW\"]\n",
        "\n",
        "    # Scale the features (important for KMeans)\n",
        "    X = StandardScaler().fit_transform(df[features])\n",
        "\n",
        "    # Fit KMeans\n",
        "    km = KMeans(n_clusters=n_clusters, random_state=42, n_init=20)\n",
        "    df[\"cluster\"] = km.fit_predict(X)\n",
        "\n",
        "    # Find which cluster corresponds to congestion\n",
        "    cluster_speed_means = df.groupby(\"cluster\")[\"SPEED_MS_AVG\"].mean()\n",
        "    congested_cluster = cluster_speed_means.idxmin()  # lowest mean speed\n",
        "\n",
        "    # Assign congestion label: 1 = congested, 0 = non-congested\n",
        "    df[\"cluster_congestion\"] = (df[\"cluster\"] == congested_cluster).astype(int)\n",
        "\n",
        "    return df, km, congested_cluster\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IWZZTtL3bl6K"
      },
      "source": [
        "#DBSCAN Method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x_sArCHxbplc"
      },
      "outputs": [],
      "source": [
        "from sklearn.cluster import DBSCAN\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "def dbscan_congestion_labeling(df, eps=0.3, min_samples=30):\n",
        "    \"\"\"\n",
        "    Unsupervised congestion labeling using DBSCAN clustering on SPEED_MS_AVG and FLOW.\n",
        "    Marks sparse/noise points (label = -1) as 'congested' = 1.\n",
        "    \"\"\"\n",
        "    df = df.copy().dropna(subset=[\"SPEED_MS_AVG\", \"FLOW\"])\n",
        "    features = [\"SPEED_MS_AVG\", \"FLOW\"]\n",
        "\n",
        "    # Scale features\n",
        "    X = StandardScaler().fit_transform(df[features])\n",
        "\n",
        "    # Fit DBSCAN\n",
        "    db = DBSCAN(eps=eps, min_samples=min_samples)\n",
        "    df[\"db_cluster\"] = db.fit_predict(X)\n",
        "\n",
        "    # DBSCAN assigns -1 to points not belonging to any cluster (noise)\n",
        "    df[\"db_congestion\"] = (df[\"db_cluster\"] == -1).astype(int)\n",
        "\n",
        "    return df, db\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LHVSQYKfLwaT"
      },
      "source": [
        "# Data prepping"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "id": "9Ik5x55hq-40"
      },
      "source": [
        "# Data Loading & Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-rVQM72Kq4ig"
      },
      "outputs": [],
      "source": [
        "tds = pd.read_csv(r\"C:\\Users\\playm\\OneDrive\\Skrivbord\\Labbar - Transport\\dataset_for_traffic_project_assignment\\training_dataset.csv\", sep=';')\n",
        "ev_ds = pd.read_csv(r\"C:\\Users\\playm\\OneDrive\\Skrivbord\\Labbar - Transport\\dataset_for_traffic_project_assignment\\evaluation_dataset.csv\", sep=';')\n",
        "f_ev_ds = pd.read_csv(r\"C:\\Users\\playm\\OneDrive\\Skrivbord\\Labbar - Transport\\dataset_for_traffic_project_assignment\\final_evaluation_dataset.csv\", sep=';')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ed8Fuwk6KpPf"
      },
      "outputs": [],
      "source": [
        "print('\\n training dataset')\n",
        "print(tds.head())\n",
        "print('\\n evaluation dataset------------')\n",
        "print(ev_ds.head())\n",
        "print('\\n final evaluation dataset --------')\n",
        "print(f_ev_ds.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f4rMw4EXL1_9"
      },
      "outputs": [],
      "source": [
        "print('Training dataset')\n",
        "print(tds.isna().sum())\n",
        "print('\\n eval dataset')\n",
        "print(ev_ds.isna().sum())\n",
        "print('\\n final eval dataset')\n",
        "print(f_ev_ds.isna().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vXWad_xvU9OW"
      },
      "outputs": [],
      "source": [
        "#drop all NaN values.\n",
        "f_ev_ds_noNAN = f_ev_ds.dropna()\n",
        "tds_noNAN = tds.dropna()\n",
        "ev_ds_noNAN = ev_ds.dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aFr7yJIwOHBx"
      },
      "outputs": [],
      "source": [
        "tds_noNAN.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dZwd0l9GMwal"
      },
      "outputs": [],
      "source": [
        "#Filter all of the datasets so we only have data from the correct portal / sensor group\n",
        "#This will ensure we can get more reliable data as the predicitons just do not work when they are all together.\n",
        "\n",
        "portal_of_interest = \"E4S 56,780\"\n",
        "tds_noNAN = tds_noNAN[tds_noNAN['PORTAL'] == portal_of_interest]\n",
        "ev_ds_noNAN = ev_ds_noNAN[ev_ds_noNAN['PORTAL'] == portal_of_interest]\n",
        "f_ev_ds_noNAN = f_ev_ds_noNAN[f_ev_ds_noNAN['PORTAL'] == portal_of_interest]\n",
        "print(f\"Training rows for {portal_of_interest}: {len(tds_noNAN)}\")\n",
        "print(f\"Evaluation rows for {portal_of_interest}: {len(ev_ds_noNAN)}\")\n",
        "print(f\"Final Evaluation rows for {portal_of_interest}: {len(f_ev_ds_noNAN)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o2L9iJoAU529"
      },
      "outputs": [],
      "source": [
        "print(f'Org dataset amount:{len(tds)}')\n",
        "print(f'Org dataset amount:{len(ev_ds)}')\n",
        "print(f'Org dataset amount:{len(f_ev_ds)}')\n",
        "\n",
        "print(f'Dropped Dataset amount:{len(tds_noNAN)}')\n",
        "print(f'Dropped Dataset amount:{len(ev_ds_noNAN)}')\n",
        "print(f'Dropped Dataset amount:{len(f_ev_ds_noNAN)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BRiwG8uAMl4N",
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "# Forts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oezW0AffMMBe"
      },
      "outputs": [],
      "source": [
        "#define what is congestion and what is not.\n",
        "# congestion_flow = tds[tds['FLOW'] < 100]\n",
        "# congestion_speed = tds[tds['SPEED_MS_AVG'] < 10]\n",
        "\n",
        "ev_ds_noNAN['datetime'] = pd.to_datetime(ev_ds_noNAN['Date'].astype(str) + ' ' + ev_ds_noNAN['Time'])\n",
        "\n",
        "ev_ds_offpeak = ev_ds_noNAN[(ev_ds_noNAN['datetime'].dt.time >= pd.to_datetime(\"04:00:00\").time()) &\n",
        "                            (ev_ds_noNAN['datetime'].dt.time <= pd.to_datetime(\"06:00:00\").time())]\n",
        "ev_ds_onpeak = ev_ds_noNAN[(ev_ds_noNAN['datetime'].dt.time >= pd.to_datetime(\"07:30:00\").time()) &\n",
        "                           (ev_ds_noNAN['datetime'].dt.time <= pd.to_datetime(\"08:30:00\").time())]\n",
        "\n",
        "ev_ds_offpeak = ev_ds_offpeak[(ev_ds_offpeak['FLOW'] > 0) &\n",
        "                              (ev_ds_offpeak['SPEED_MS_AVG'].between(5, 50))]\n",
        "ev_ds_onpeak = ev_ds_onpeak[(ev_ds_onpeak['FLOW'] > 0) &\n",
        "                            (ev_ds_onpeak['SPEED_MS_AVG'].between(5, 50))]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ou3DA0M5VJKf"
      },
      "outputs": [],
      "source": [
        "# converting the date and time columns int o just one \"datetime\" coluinm\n",
        "tds_noNAN['datetime'] = pd.to_datetime(tds_noNAN['Date'].astype(str) + ' ' + tds_noNAN['Time'])\n",
        "\n",
        "# filtering the dataset to only include the data within hours 04:00 and 06:00, this to get an accurate description of free flow speed.\n",
        "tds_offpeak = tds_noNAN[(tds_noNAN['datetime'].dt.time >= pd.to_datetime(\"04:00:00\").time()) &\n",
        "                (tds_noNAN['datetime'].dt.time <= pd.to_datetime(\"06:00:00\").time())]\n",
        "\n",
        "tds_onpeak= tds_noNAN[(tds_noNAN['datetime'].dt.time >= pd.to_datetime(\"07:30:00\").time()) &\n",
        "                  (tds_noNAN['datetime'].dt.time <= pd.to_datetime(\"08:30:00\").time())]\n",
        "#Ensuring we only get correctly read speeds. E.g Removing any negative speeds and random slow drivers etc\n",
        "#that do not actually depict the actual free flowspeed e.g people speeding and drinving super slow...\n",
        "tds_offpeak = tds_offpeak[(tds_offpeak['FLOW'] > 0) &\n",
        "                        (tds_offpeak['SPEED_MS_AVG'].between(2, 50))]\n",
        "tds_onpeak = tds_onpeak[(tds_onpeak['FLOW'] > 0) &\n",
        "                        (tds_onpeak['SPEED_MS_AVG'].between(2, 50))]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ElMYH5w4q-42"
      },
      "source": [
        "#  Modeling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pqte_MKeeSJi"
      },
      "outputs": [],
      "source": [
        "#defining what congestion is for off peak hours\n",
        "ffs_kmh = 85 #Through basic theory, a 4 lane road with a speed limit of 70 km/h, would have the free flow speed around 85 km/h\n",
        "ffs_ms = ffs_kmh * 0.277778 # Converting km/h to m/s\n",
        "cong_th = (ffs_kmh * 0.7) # We use mild congestion as a staple, as otherwise the dataset for congested times is just to small to work with.\n",
        "print(f\"Free flow speed in [km/h]: {ffs_kmh}\")\n",
        "print(f\"Free flow speed in [m/s]: {ffs_ms}\")\n",
        "print(f\"Congestion Speed Threshold [km/h]: {cong_th}\")\n",
        "\n",
        "#hard coding cong as 60 [km/h] for simplicty\n",
        "cong_th_2 = 61"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ArMy7NEYcvl_"
      },
      "outputs": [],
      "source": [
        "#defining what congestion is for on peak hours\n",
        "ffs_kmh_2 = 85 #Through basic theory, a 4 lane road with a speed limit of 70 km/h, would have the free flow speed around 85 km/h\n",
        "ffs_ms_2 = ffs_kmh_2 * 0.277778 # Converting km/h to m/s\n",
        "cong_th_2 = (ffs_kmh_2 * 0.7) # We use mild congestion as a staple, as otherwise the dataset for congested times is just to small to work with.\n",
        "print(f\"Free flow speed in [km/h]: {ffs_kmh_2}\")\n",
        "print(f\"Free flow speed in [m/s]: {ffs_ms_2}\")\n",
        "print(f\"Congestion Speed Threshold [km/h]: {cong_th_2}\")\n",
        "\n",
        "#hard coding cong as 61 [km/h] for simplicty and to catch those going around 60km/h for a fairer comparison\n",
        "cong_th_2 = 61"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R5ParPnNbdFN"
      },
      "outputs": [],
      "source": [
        "print(cong_th_2)\n",
        "tds_onpeak.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qScNu1yw0KIE"
      },
      "outputs": [],
      "source": [
        "#Creat our rolling and shifting.\n",
        "tds_onpeak['pred15'] = tds_onpeak['SPEED_MS_AVG'].shift(-1).rolling(15).mean()\n",
        "tds_onpeak['congestion'] = (tds_onpeak['pred15']*3.6 <= cong_th_2).astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jGTgbppNBiE7"
      },
      "outputs": [],
      "source": [
        "tds_onpeak[\"speed_norm\"] = (\n",
        "    tds_onpeak.groupby(\"DP_ID\")[\"SPEED_MS_AVG\"]\n",
        "    .transform(lambda x: (x - x.mean()) / x.std())\n",
        ")\n",
        "\n",
        "ev_ds_onpeak[\"speed_norm\"] = (\n",
        "    ev_ds_onpeak.groupby(\"DP_ID\")[\"SPEED_MS_AVG\"]\n",
        "    .transform(lambda x: (x - x.mean()) / x.std())\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dd_DcqZwcxLT",
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "# Methods for classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3DSsQmmiaYw9"
      },
      "source": [
        "## pca Version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ld_uOZiAp37E"
      },
      "outputs": [],
      "source": [
        "tds_pca, error_threshold = pca_anomaly_labeling(tds_onpeak, n_components=2, contamination=0.15)\n",
        "print(f\"PCA anomaly threshold: {error_threshold:.6f}\")\n",
        "print(tds_pca[\"pca_congestion\"].value_counts())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sGFQ4cUoaadw",
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "## Clustering Version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8vXvOrjVadT0"
      },
      "outputs": [],
      "source": [
        "tds_cluster, kmeans_model, congested_cluster = kmeans_congestion_labeling(tds_onpeak, n_clusters=3)\n",
        "print(\"Congested cluster:\", congested_cluster)\n",
        "print(tds_cluster[\"cluster_congestion\"].value_counts())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q7ycM2CIamlV"
      },
      "outputs": [],
      "source": [
        "#visualisation of clusters\n",
        "plt.figure(figsize=(8,5))\n",
        "sns.scatterplot(\n",
        "    data=tds_cluster,\n",
        "    x=tds_cluster[\"SPEED_MS_AVG\"]*3.6,  # convert to km/h\n",
        "    y=tds_cluster[\"FLOW\"],\n",
        "    hue=tds_cluster[\"cluster\"],\n",
        "    palette=\"viridis\",\n",
        "    alpha=0.6\n",
        ")\n",
        "plt.xlabel(\"Speed (km/h)\")\n",
        "plt.ylabel(\"Flow (veh/h)\")\n",
        "plt.title(\"Traffic states discovered by K-means clustering\")\n",
        "plt.legend(title=\"Cluster\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1xYNAEVgb2lL",
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "## DBSCAN Method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0t1KWGvpb7XT"
      },
      "outputs": [],
      "source": [
        "tds_db, db_model = dbscan_congestion_labeling(tds_onpeak, eps=0.25, min_samples=20)\n",
        "print(tds_db[\"db_congestion\"].value_counts())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5suVQ8MXb867"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "sns.scatterplot(\n",
        "    x=tds_db[\"SPEED_MS_AVG\"] * 3.6,  # convert m/s â†’ km/h\n",
        "    y=tds_db[\"FLOW\"],\n",
        "    hue=tds_db[\"db_congestion\"],\n",
        "    palette={0:\"skyblue\", 1:\"red\"},\n",
        "    alpha=0.6\n",
        ")\n",
        "plt.xlabel(\"Speed (km/h)\")\n",
        "plt.ylabel(\"Flow (veh/h)\")\n",
        "plt.title(\"DBSCAN-based congestion labeling (red = anomalous/congested)\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dXr80z4Fb9_A"
      },
      "source": [
        "# Hard constrained function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sLWdQaYioobp"
      },
      "outputs": [],
      "source": [
        "#function where the features are created and..\n",
        "def make_features_targets(df, horizon=15, window=15, cong_th_2=61):\n",
        "    df = df.copy()\n",
        "    df = df.sort_values(\"datetime\")\n",
        "\n",
        "    # Ensure so the df is in datetime and not Date and Time..\n",
        "    if \"datetime\" not in df.columns:\n",
        "        df[\"datetime\"] = pd.to_datetime(df[\"Date\"].astype(str) + \" \" + df[\"Time\"])\n",
        "\n",
        "    # Rolling past features\n",
        "    df[\"past_mean_speed\"] = df[\"SPEED_MS_AVG\"].rolling(window).mean()\n",
        "    df[\"past_std_speed\"] = df[\"SPEED_MS_AVG\"].rolling(window).std()\n",
        "    df[\"past_min_speed\"] = df[\"SPEED_MS_AVG\"].rolling(window).min()\n",
        "\n",
        "    df[\"past_mean_flow\"] = df[\"FLOW\"].rolling(window).mean()\n",
        "    df[\"past_std_flow\"] = df[\"FLOW\"].rolling(window).std()\n",
        "\n",
        "    #\n",
        "    df[\"past_speed_trend\"] = df[\"SPEED_MS_AVG\"] - df[\"SPEED_MS_AVG\"].rolling(window).mean()\n",
        "    df[\"flow_to_speed_ratio\"] = df[\"past_mean_flow\"] / (df[\"past_mean_speed\"] + 1e-3)\n",
        "\n",
        "    # Share of low-speed observations\n",
        "    df[\"share_low_speed\"] = (\n",
        "        (df[\"SPEED_MS_AVG\"] * 3.6 < cong_th_2)\n",
        "        .rolling(window)\n",
        "        .mean()\n",
        "    )\n",
        "\n",
        "    # tem.poral features.\n",
        "    df[\"hour\"] = df[\"datetime\"].dt.hour\n",
        "    df[\"month\"] = df[\"datetime\"].dt.month\n",
        "    df[\"dayofweek\"] = df[\"datetime\"].dt.dayofweek\n",
        "\n",
        "    df[\"hour_sin\"] = np.sin(2 * np.pi * df[\"hour\"] / 24)\n",
        "    df[\"hour_cos\"] = np.cos(2 * np.pi * df[\"hour\"] / 24)\n",
        "    df[\"month_sin\"] = np.sin(2 * np.pi * df[\"month\"] / 12)\n",
        "    df[\"month_cos\"] = np.cos(2 * np.pi * df[\"month\"] / 12)\n",
        "    df[\"dow_sin\"] = np.sin(2 * np.pi * df[\"dayofweek\"] / 7)\n",
        "    df[\"dow_cos\"] = np.cos(2 * np.pi * df[\"dayofweek\"] / 7)\n",
        "\n",
        "    # target, future congestion. Hard constrained to our cong_th_2\n",
        "    future_speed = df[\"SPEED_MS_AVG\"].shift(-horizon).rolling(horizon).mean()\n",
        "    df[\"future_congestion\"] = (future_speed * 3.6 < cong_th_2).astype(int)\n",
        "\n",
        "    # Speed and flow deltas\n",
        "    df[\"speed_delta_5min\"] = df[\"SPEED_MS_AVG\"] - df[\"SPEED_MS_AVG\"].shift(5)\n",
        "    df[\"flow_delta_5min\"] = df[\"FLOW\"] - df[\"FLOW\"].shift(5)\n",
        "\n",
        "    # Rolling slope of speed\n",
        "    df[\"speed_slope\"] = (\n",
        "    df[\"SPEED_MS_AVG\"].rolling(5)\n",
        "      .apply(lambda x: np.polyfit(range(len(x)), x, 1)[0], raw=False)\n",
        "    )\n",
        "\n",
        "    # dropping eventual nans created during the process\n",
        "    df = df.dropna().reset_index(drop=True)\n",
        "\n",
        "    # testing feature block.\n",
        "    # features = [\n",
        "        # \"past_mean_speed\", \"past_std_speed\", \"past_min_speed\",\n",
        "        # \"past_mean_flow\", \"past_std_flow\",\n",
        "        # \"past_speed_trend\", \"flow_to_speed_ratio\",\n",
        "        # \"share_low_speed\",\n",
        "        # \"hour_sin\", \"hour_cos\",\n",
        "        # \"month_sin\", \"month_cos\",\n",
        "        # \"dow_sin\", \"dow_cos\",'speed_slope','speed_delta_5min','flow_delta_5min']\n",
        "\n",
        "# these are the only features used\n",
        "    features = [\n",
        "        \"past_mean_speed\", \"past_std_speed\", \"past_min_speed\",\n",
        "        \"past_speed_trend\",\n",
        "        \"share_low_speed\",\n",
        "        \"hour_sin\", \"hour_cos\",\n",
        "        \"month_sin\", \"month_cos\",\n",
        "        \"dow_sin\", \"dow_cos\",'speed_slope','speed_delta_5min','flow_delta_5min'\n",
        "        ]\n",
        "\n",
        "    target = \"future_congestion\"\n",
        "\n",
        "    return df, features, target\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gIlRzi2lcBRJ",
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "## Initate the methods\n",
        "\n",
        "Run only one, aka the chosen method code block."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5pCZiowXHPdv"
      },
      "outputs": [],
      "source": [
        "tds_fixad, features, target = make_features_targets(tds_onpeak, horizon=15, cong_th_2=cong_th_2)\n",
        "\n",
        "# Create evaluation data (for 2022)\n",
        "ev_fixad, _, _ = make_features_targets(ev_ds_onpeak, horizon=15, cong_th_2=cong_th_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jVR9Q9q2YYe4"
      },
      "outputs": [],
      "source": [
        "tds_pca, error_threshold = pca_anomaly_labeling(tds_onpeak, n_components=2, contamination=0.15)\n",
        "tds_fixad, features, target = make_features_targets(tds_pca, horizon=15)\n",
        "tds_fixad[\"future_congestion\"] = tds_pca[\"pca_congestion\"].iloc[:len(tds_fixad)].values\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6LJd0bCHa1Ma"
      },
      "outputs": [],
      "source": [
        "tds_cluster, _, _ = kmeans_congestion_labeling(tds_onpeak, n_clusters=3)\n",
        "tds_fixad, features, target = make_features_targets(tds_cluster, horizon=15)\n",
        "tds_fixad[\"future_congestion\"] = tds_cluster[\"cluster_congestion\"].iloc[:len(tds_fixad)].values\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1FNpRzfzcSVY"
      },
      "outputs": [],
      "source": [
        "tds_db, db_model = dbscan_congestion_labeling(tds_onpeak, eps=0.25, min_samples=20)\n",
        "tds_fixad, features, target = make_features_targets(tds_db, horizon=15)\n",
        "tds_fixad[\"future_congestion\"] = tds_db[\"db_congestion\"].iloc[:len(tds_fixad)].values\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7L7zGdNjSYbq"
      },
      "source": [
        "# Dela upp i train test splits."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wsZWjSzpKOQI"
      },
      "outputs": [],
      "source": [
        "#Split into train / test sets\n",
        "X = tds_fixad[features].values\n",
        "y = tds_fixad[target].values\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=False)\n",
        "#Scaling the datat.\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled  = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qjbV9vQfLA_t"
      },
      "source": [
        "# Test data models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ftEGsokKqdI"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "#Logistic regression model.\n",
        "lr = LogisticRegression(random_state = 42, max_iter = 1000, class_weight='balanced')\n",
        "lr.fit(X_train_scaled, y_train)\n",
        "y_pred_lr = lr.predict(X_test_scaled)\n",
        "y_prob_lr = lr.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "print(\"Logistic Regression Dataset\")\n",
        "print(confusion_matrix(y_test, y_pred_lr))\n",
        "print(classification_report(y_test, y_pred_lr, digits=3))\n",
        "print(f\" The roc_auc score is: {roc_auc_score(y_test, y_prob_lr)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b0dd6e72"
      },
      "outputs": [],
      "source": [
        "print(\"Class distribution in y_train:\")\n",
        "print(pd.Series(y_train).value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0c060018"
      },
      "outputs": [],
      "source": [
        "print(\"Class distribution in tds_fixad['future_congestion']:\")\n",
        "print(tds_fixad['future_congestion'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EgkS9CZMaTzb"
      },
      "outputs": [],
      "source": [
        "from xgboost import XGBClassifier\n",
        "#Xgboos classifier.\n",
        "scale_pos_weight = (len(y_train) - sum(y_train)) / sum(y_train)\n",
        "xgb_clf = XGBClassifier(\n",
        "    n_estimators=500,\n",
        "    learning_rate=0.03,\n",
        "    max_depth=3,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.8,\n",
        "    scale_pos_weight=scale_pos_weight,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        "    )\n",
        "\n",
        "xgb_clf.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Predict.\n",
        "y_pred_xgb = xgb_clf.predict(X_test_scaled)\n",
        "y_prob_xgb = xgb_clf.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "\n",
        "# stats\n",
        "print(\"XGBoost Training dataset\")\n",
        "print(confusion_matrix(y_test, y_pred_xgb))\n",
        "print(classification_report(y_test, y_pred_xgb, digits=3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z0FnSQBggD_Y"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rf_clf = RandomForestClassifier(\n",
        "    n_estimators=400,\n",
        "    max_depth=2,\n",
        "    class_weight='balanced',  # handle the class imbalance\n",
        "    random_state=42,\n",
        "    n_jobs=-1 #n_jobs help using all cores.\n",
        "    )\n",
        "\n",
        "rf_clf.fit(X_train_scaled, y_train)\n",
        "y_pred_rf = rf_clf.predict(X_test_scaled)\n",
        "#stats\n",
        "print(\"Random Forest Training dataset\")\n",
        "print(confusion_matrix(y_test, y_pred_rf))\n",
        "print(classification_report(y_test, y_pred_rf, digits=3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "49ZTFMEe7JPI"
      },
      "outputs": [],
      "source": [
        "rf_clf = RandomForestClassifier(\n",
        "    n_estimators=400,\n",
        "    max_depth=8,\n",
        "    min_samples_split=5,\n",
        "    min_samples_leaf=3,\n",
        "    max_features='sqrt',\n",
        "    class_weight={0:1, 1:2},\n",
        "    criterion='entropy',\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "rf_clf.fit(X_train_scaled, y_train)\n",
        "y_prob_rf = rf_clf.predict_proba(X_test_scaled)[:, 1]\n",
        "y_pred_rf = (y_prob_rf >= 0.4).astype(int)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AqljudGC74Yc"
      },
      "outputs": [],
      "source": [
        "print(\"Random Forest Training dataset\")\n",
        "print(confusion_matrix(y_test, y_pred_rf))\n",
        "print(classification_report(y_test, y_pred_rf, digits=3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mGcsbQF4TpQw"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVC\n",
        "#Support vector classifier.\n",
        "svm = SVC(\n",
        "    kernel='rbf',\n",
        "    probability=True,\n",
        "    C=0.5,\n",
        "    gamma='scale',\n",
        "    random_state=42,\n",
        "    class_weight={0: 1, 1: 2}\n",
        "    )\n",
        "\n",
        "svm.fit(X_train_scaled, y_train)\n",
        "y_pred_svm = svm.predict(X_test_scaled)\n",
        "y_prob_svm = svm.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "#stats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yV9zu3CcfGTI"
      },
      "outputs": [],
      "source": [
        "print('SVM Training Dataset')\n",
        "print(confusion_matrix(y_test, y_pred_svm))\n",
        "print(classification_report(y_test, y_pred_svm, digits=3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mnTp4Snidn_5"
      },
      "outputs": [],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# Initialize and train the KNN classifier\n",
        "knn_clf = KNeighborsClassifier(n_neighbors=5, weights='distance', metric='minkowski', n_jobs=-1) # You can adjust n_neighbors\n",
        "knn_clf.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred_knn = knn_clf.predict(X_test_scaled)\n",
        "\n",
        "# Print evaluation metrics\n",
        "print(\"K-Nearest Neighbors Training dataset\")\n",
        "print(confusion_matrix(y_test, y_pred_knn))\n",
        "print(classification_report(y_test, y_pred_knn, digits=3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tw46yVd8pU2a"
      },
      "outputs": [],
      "source": [
        "print(\"Logistic Regression Dataset\")\n",
        "print(confusion_matrix(y_test, y_pred_lr))\n",
        "print(classification_report(y_test, y_pred_lr, digits=3))\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"XGBoost Training dataset\")\n",
        "print(confusion_matrix(y_test, y_pred_xgb))\n",
        "print(classification_report(y_test, y_pred_xgb, digits=3))\n",
        "print(\"\\n\")\n",
        "print(\"Random Forest Training dataset\")\n",
        "print(confusion_matrix(y_test, y_pred_rf))\n",
        "print(classification_report(y_test, y_pred_rf, digits=3))\n",
        "print(\"\\n\")\n",
        "print(\"SVM Training dataset\")\n",
        "print(confusion_matrix(y_test, y_pred_svm))\n",
        "print(classification_report(y_test, y_pred_svm, digits=3))\n",
        "print('\\n')\n",
        "print(\"K-Nearest Neighbors Training dataset\")\n",
        "print(confusion_matrix(y_test, y_pred_knn))\n",
        "print(classification_report(y_test, y_pred_knn, digits=3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-3eeZRo2gZLE"
      },
      "outputs": [],
      "source": [
        "#create empty list to store results\n",
        "results = []\n",
        "\n",
        "#for loop that adds results to the list \"results\"\n",
        "for name, pred in [\n",
        "    (\"Logistic Regression\", y_pred_lr),\n",
        "    (\"Random Forest\", y_pred_rf),\n",
        "    (\"XGBoost\", y_pred_xgb),\n",
        "    (\"SVM\", y_pred_svm),\n",
        "    (\"K-Nearest Neighbors\", y_pred_knn)\n",
        "]:\n",
        "    results.append({\n",
        "        \"Model\": name,\n",
        "        \"Accuracy\": accuracy_score(y_test, pred),\n",
        "        \"Precision\": precision_score(y_test, pred),\n",
        "        \"Recall\": recall_score(y_test, pred),\n",
        "        \"F1\": f1_score(y_test, pred)\n",
        "    })\n",
        "\n",
        "results_df = pd.DataFrame(results)\n",
        "#print the results.\n",
        "print(results_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJ5vt7NRq-5E"
      },
      "source": [
        "## GridSearching\n",
        "\n",
        "For clarity this part was helped by generative AI."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iKoxO1cnq-5E"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import (\n",
        "    f1_score, precision_score, recall_score,\n",
        "    classification_report, confusion_matrix,\n",
        "    precision_recall_curve, make_scorer\n",
        ")\n",
        "\n",
        "def train_and_evaluate_model(model, model_name, param_grid,\n",
        "                             X_train_scaled, y_train,\n",
        "                             X_test_scaled, y_test,\n",
        "                             scoring_metric='f1',\n",
        "                             threshold_tuning=True,\n",
        "                             show_plots=True):\n",
        "    \"\"\"\n",
        "    Trains any model using GridSearchCV, tunes threshold for best F1,\n",
        "    and prints performance + plots precision-recall curve.\n",
        "    \"\"\"\n",
        "\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\" Starting Grid Search + Evaluation for {model_name}\")\n",
        "    print(f\"{'='*80}\")\n",
        "\n",
        "    # Grid Searching  all models\n",
        "    scorer = make_scorer(f1_score, pos_label=1)\n",
        "    grid = GridSearchCV(model, param_grid, scoring=scorer, cv=3, n_jobs=-1, verbose=2)\n",
        "    grid.fit(X_train_scaled, y_train)\n",
        "\n",
        "    best_model = grid.best_estimator_\n",
        "    best_params = grid.best_params_\n",
        "    print(f\"\\n Best parameters for {model_name}: {best_params}\")\n",
        "    print(f\" Best CV F1-score: {grid.best_score_:.3f}\")\n",
        "\n",
        "    #  probabilities  scores\n",
        "    if hasattr(best_model, \"predict_proba\"):\n",
        "        y_prob = best_model.predict_proba(X_test_scaled)[:, 1]\n",
        "    elif hasattr(best_model, \"decision_function\"):\n",
        "        y_scores = best_model.decision_function(X_test_scaled)\n",
        "        y_prob = 1 / (1 + np.exp(-y_scores))\n",
        "    else:\n",
        "        y_prob = best_model.predict(X_test_scaled)\n",
        "        threshold_tuning = False\n",
        "        print(\"Model has no probability outputs: skipping threshold tuning.\")\n",
        "\n",
        "    # hreshold tuning for best F1\n",
        "    if threshold_tuning:\n",
        "        thresholds = np.arange(0.1, 0.9, 0.02)\n",
        "        f1_scores = [f1_score(y_test, (y_prob >= t).astype(int)) for t in thresholds]\n",
        "        best_t = thresholds[np.argmax(f1_scores)]\n",
        "        best_f1 = np.max(f1_scores)\n",
        "        print(f\"Best threshold = {best_t:.2f} (F1 = {best_f1:.3f})\")\n",
        "    else:\n",
        "        best_t = 0.5\n",
        "\n",
        "    # Evaluate the models\n",
        "    y_pred = (y_prob >= best_t).astype(int)\n",
        "    print(\"\\nðŸ“Š Confusion Matrix:\")\n",
        "    print(confusion_matrix(y_test, y_pred))\n",
        "    print(f\"\\nðŸ“‹ Classification Report ({model_name}):\")\n",
        "    print(classification_report(y_test, y_pred, digits=3))\n",
        "\n",
        "    # Stores the results in a list..\n",
        "    results = {\n",
        "        \"model_name\": model_name,\n",
        "        \"best_params\": best_params,\n",
        "        \"best_threshold\": best_t,\n",
        "        \"precision\": precision_score(y_test, y_pred),\n",
        "        \"recall\": recall_score(y_test, y_pred),\n",
        "        \"f1\": f1_score(y_test, y_pred),\n",
        "        \"model\": best_model\n",
        "    }\n",
        "\n",
        "    # Plot precision-recall curve for easy visualizxation of the models performances.\n",
        "    if show_plots and threshold_tuning:\n",
        "        prec, rec, thr = precision_recall_curve(y_test, y_prob)\n",
        "        plt.figure(figsize=(6, 5))\n",
        "        plt.plot(rec, prec, label=\"Precisionâ€“Recall Curve\")\n",
        "        plt.axvline(x=results[\"recall\"], color='r', linestyle='--', label=f\"Recall = {results['recall']:.2f}\")\n",
        "        plt.axhline(y=results[\"precision\"], color='g', linestyle='--', label=f\"Precision = {results['precision']:.2f}\")\n",
        "        plt.title(f\"{model_name} Precisionâ€“Recall Curve\")\n",
        "        plt.xlabel(\"Recall\")\n",
        "        plt.ylabel(\"Precision\")\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "        plt.show()\n",
        "\n",
        "    return results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yqsGWdn0q-5F"
      },
      "outputs": [],
      "source": [
        "# defining what parameters we are looking for to get the best results.\n",
        "param_grids = {\n",
        "    \"Logistic Regression\": {\n",
        "        \"model\": LogisticRegression(max_iter=500, class_weight='balanced', solver='lbfgs', random_state=42),\n",
        "        \"params\": {\n",
        "            \"C\": [0.1, 1, 5, 10],\n",
        "            \"penalty\": [\"l2\"]\n",
        "        }\n",
        "    },\n",
        "\n",
        "    \"Random Forest\": {\n",
        "        \"model\": RandomForestClassifier(random_state=42, n_jobs=-1),\n",
        "        \"params\": {\n",
        "            \"n_estimators\": [200, 400],\n",
        "            \"max_depth\": [4, 6, 8, None],\n",
        "            \"min_samples_split\": [2, 5],\n",
        "            \"min_samples_leaf\": [1, 3, 5],\n",
        "            \"class_weight\": [\"balanced\", {0:1, 1:2}],\n",
        "            \"criterion\": [\"gini\", \"entropy\"]\n",
        "        }\n",
        "    },\n",
        "\n",
        "    \"XGBoost\": {\n",
        "        \"model\": XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42),\n",
        "        \"params\": {\n",
        "            \"n_estimators\": [200, 400],\n",
        "            \"max_depth\": [4, 6, 8],\n",
        "            \"learning_rate\": [0.05, 0.1, 0.2],\n",
        "            \"subsample\": [0.8, 1.0],\n",
        "            \"colsample_bytree\": [0.8, 1.0],\n",
        "            \"scale_pos_weight\": [1, 2, 3]\n",
        "        }\n",
        "    },\n",
        "\n",
        "    \"Support Vector Machine\": {\n",
        "        \"model\": SVC(probability=True, random_state=42),\n",
        "        \"params\": {\n",
        "            \"C\": [0.5, 1, 2],\n",
        "            \"gamma\": [\"scale\", \"auto\"],\n",
        "            \"kernel\": [\"rbf\", \"poly\"]\n",
        "        }\n",
        "    },\n",
        "\n",
        "    \"K-Nearest Neighbors\": {\n",
        "        \"model\": KNeighborsClassifier(n_jobs=-1),\n",
        "        \"params\": {\n",
        "            \"n_neighbors\": [3, 5, 7, 9],\n",
        "            \"weights\": [\"uniform\", \"distance\"],\n",
        "            \"metric\": [\"minkowski\", \"euclidean\"]\n",
        "        }\n",
        "    }\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Bd29Rqeq-5F"
      },
      "outputs": [],
      "source": [
        "results = []\n",
        "\n",
        "for name, setup in param_grids.items():\n",
        "    res = train_and_evaluate_model(\n",
        "        setup[\"model\"],\n",
        "        model_name=name,\n",
        "        param_grid=setup[\"params\"],\n",
        "        X_train_scaled=X_train_scaled,\n",
        "        y_train=y_train,\n",
        "        X_test_scaled=X_test_scaled,\n",
        "        y_test=y_test,\n",
        "        scoring_metric='f1',\n",
        "        threshold_tuning=True,\n",
        "        show_plots=True\n",
        "    )\n",
        "    results.append(res)\n",
        "\n",
        "# Comparison table\n",
        "results_df = pd.DataFrame(results)[[\"model_name\", \"precision\", \"recall\", \"f1\", \"best_threshold\", \"best_params\"]]\n",
        "print(\"\\n Model Comparison Summary:\")\n",
        "print(results_df.sort_values(by=\"f1\", ascending=False).to_string(index=False))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MSdFxjEtpMlD"
      },
      "source": [
        "# Evaluation data models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jk-WpHX1pPPO"
      },
      "outputs": [],
      "source": [
        "#call function to fix ev_ds_onpeak dataset to contain the same features.\n",
        "ev_fixad, _, _ = make_features_targets(ev_ds_onpeak, horizon=15, cong_th_2=cong_th_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ROpodssNq-5F"
      },
      "outputs": [],
      "source": [
        "#running the models on the evaluation dataset.\n",
        "X_eval = ev_fixad[features].values\n",
        "y_eval = ev_fixad[target].values\n",
        "\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train)\n",
        "X_train_scaled = scaler.transform(X_train)\n",
        "X_eval_scaled  = scaler.transform(X_eval)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LznoD6WWpUNy"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "for name, model in [\n",
        "    (\"Logistic Regression\", lr),\n",
        "    (\"Random Forest\", rf_clf),\n",
        "    (\"XGBoost\", xgb_clf),\n",
        "    (\"SVM\", svm)\n",
        "]:\n",
        "    y_pred_eval = model.predict(X_eval_scaled)\n",
        "    print(f\"\\n{name} (Evaluation 2022 dataset):\")\n",
        "    print(confusion_matrix(y_eval, y_pred_eval))\n",
        "    print(classification_report(y_eval, y_pred_eval, digits=3))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KKgaNypCpXxp"
      },
      "outputs": [],
      "source": [
        "#loop through models on evaluation dataset.\n",
        "for name, model in [\n",
        "    (\"Logistic Regression\", lr),\n",
        "    (\"Random Forest\", rf_clf),\n",
        "    (\"XGBoost\", xgb_clf),\n",
        "    (\"SVM\", svm)\n",
        "]:\n",
        "    y_pred_eval = model.predict(X_eval_scaled)\n",
        "    print(f\"\\n{name} (Evaluation 2022 dataset):\")\n",
        "    print(confusion_matrix(y_eval, y_pred_eval))\n",
        "    print(classification_report(y_eval, y_pred_eval, digits=3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-o_RFenXRqTZ"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import precision_recall_curve\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "# Filter the final evaluation dataset by the portal of interest\n",
        "f_ev_ds_portal = f_ev_ds[f_ev_ds['PORTAL'] == portal_of_interest].copy()\n",
        "\n",
        "# Drop NaNs from f_ev_ds_portal before feature engineering\n",
        "f_ev_ds_cleaned = f_ev_ds_portal.dropna(subset=[\"SPEED_MS_AVG\", \"FLOW\"]).copy()\n",
        "\n",
        "# Ensure datetime is present\n",
        "if \"datetime\" not in f_ev_ds_cleaned.columns:\n",
        "    f_ev_ds_cleaned[\"datetime\"] = pd.to_datetime(f_ev_ds_cleaned[\"Date\"].astype(str) + \" \" + f_ev_ds_cleaned[\"Time\"])\n",
        "\n",
        "# Filter again for peak hours\n",
        "f_ev_ds_onpeak = f_ev_ds_cleaned[\n",
        "    (f_ev_ds_cleaned['datetime'].dt.time >= pd.to_datetime(\"07:30:00\").time()) &\n",
        "    (f_ev_ds_cleaned['datetime'].dt.time <= pd.to_datetime(\"08:30:00\").time())\n",
        "].copy()\n",
        "\n",
        "# # Use the make_features_targets function on the filtered (onpeak) data set for final evaluation.\n",
        "# f_ev_fixad, features_eval, target_eval = make_features_targets(\n",
        "#     f_ev_ds_onpeak, horizon=15, cong_th_2=cong_th_2\n",
        "# )\n",
        "\n",
        "\n",
        "X_final_eval = f_ev_fixad[features_eval].values\n",
        "y_final_eval = f_ev_fixad[target_eval].values\n",
        "\n",
        "#Scaling final evaluation data.\n",
        "# Scaler for threshold.\n",
        "scaler_threshold = StandardScaler()\n",
        "X_train_threshold = tds_fixad[features_eval].values\n",
        "scaler_threshold.fit(X_train_threshold)\n",
        "X_final_eval_scaled = scaler_threshold.transform(X_final_eval)\n",
        "\n",
        "\n",
        "# # Evaluation of traning models on the final evaluation dataset\n",
        "# print(\"\\nEvaluating models on f_ev_ds (threshold labels):\")\n",
        "# # Use the models trained with the threshold-based labels (lr, rf_clf, xgb_clf from earlier cells)\n",
        "# models_threshold = [(\"Logistic Regression\", lr), (\"Random Forest\", rf_clf), (\"XGBoost\", xgb_clf), (\"SVM\", svm), (\"K-Nearest Neighbors\", knn_clf)]\n",
        "\n",
        "# # Get probability predictions for each model on the final evaluation dataset\n",
        "# y_prob_final_eval = {}\n",
        "# for name, model in models_threshold:\n",
        "#     y_pred_final_eval = model.predict(X_final_eval_scaled)\n",
        "#     y_prob_final_eval[name] = model.predict_proba(X_final_eval_scaled)[:, 1]\n",
        "\n",
        "#     print(f\"\\n{name} (Final Evaluation f_ev_ds with threshold labels):\")\n",
        "#     print(confusion_matrix(y_final_eval, y_pred_final_eval))\n",
        "#     print(classification_report(y_final_eval, y_pred_final_eval, digits=3))\n",
        "#     print(\"F1-score:\", round(f1_score(y_final_eval, y_pred_final_eval), 3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W9-kkwyYhC2V"
      },
      "source": [
        "# Visualizations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yoBXgQo-hG_U"
      },
      "source": [
        "## Training Data Visualisations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xxLyeXYXhE1a"
      },
      "outputs": [],
      "source": [
        "#Scatter plot, flow vs speed on training data.\n",
        "sns.scatterplot(\n",
        "    data=tds_fixad,\n",
        "    x='past_mean_flow',\n",
        "    y='past_mean_speed',\n",
        "    hue='future_congestion',\n",
        "    alpha=0.3\n",
        ")\n",
        "plt.title('Flow vs Speed (Training Data)')\n",
        "plt.xlabel('Average Flow (veh/min)')\n",
        "plt.ylabel('Average Speed (m/s)')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "610cA_kkhKMo"
      },
      "source": [
        "## Evaluation set 1 visualisations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "18TWkyKChOIo"
      },
      "source": [
        "## Final Evaluation set visualisations.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KmKoAsbrhUZ2"
      },
      "outputs": [],
      "source": [
        "#percision and recall curves for the final evaluation dataset\n",
        "plt.figure(figsize=(8, 6))\n",
        "\n",
        "for name, y_prob in y_prob_final_eval.items():\n",
        "    prec, rec, thr = precision_recall_curve(y_final_eval, y_prob)\n",
        "    plt.plot(rec, prec, label=name)\n",
        "\n",
        "plt.xlabel(\"Recall (True Positive Rate)\")\n",
        "plt.ylabel(\"Precision\")\n",
        "plt.title(\"Precisionâ€“Recall Curves â€“ Model Comparison (Final Evaluation f_ev_ds)\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3RPsGKWun1iF"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Get feature importances from the trained Random Forest\n",
        "importances = rf_clf.feature_importances_\n",
        "\n",
        "# Combine with feature names\n",
        "feature_importance_df = pd.DataFrame({\n",
        "    'Feature': features,\n",
        "    'Importance': importances\n",
        "}).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "print(feature_importance_df.head(10))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W3kYUhYPqCMy"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Get feature importances from the trained Random Forest\n",
        "importances = xgb_clf.feature_importances_\n",
        "\n",
        "# Combine with feature names\n",
        "feature_importance_df = pd.DataFrame({\n",
        "    'Feature': features,\n",
        "    'Importance': importances\n",
        "}).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "print(feature_importance_df.head(10))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aUg9kM13oY3T"
      },
      "outputs": [],
      "source": [
        "from sklearn.inspection import permutation_importance\n",
        "\n",
        "result = permutation_importance(rf_clf, X_test_scaled, y_test, n_repeats=10, random_state=42)\n",
        "sorted_idx = result.importances_mean.argsort()[::-1]\n",
        "\n",
        "for idx in sorted_idx[:10]:\n",
        "    print(features[idx], result.importances_mean[idx])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1HBCe7UC9Bs7"
      },
      "outputs": [],
      "source": [
        "for res in results:\n",
        "    model = res[\"model\"]\n",
        "    threshold = res[\"best_threshold\"]\n",
        "    name = res[\"model_name\"]\n",
        "\n",
        "    if hasattr(model, \"predict_proba\"):\n",
        "        y_prob_eval = model.predict_proba(X_eval_scaled)[:, 1]\n",
        "        y_pred_eval = (y_prob_eval >= threshold).astype(int)\n",
        "    else:\n",
        "        y_pred_eval = model.predict(X_eval_scaled)\n",
        "\n",
        "    print(f\"\\n {name} (Evaluation Dataset 2022 metrics results):\")\n",
        "    print(confusion_matrix(y_eval, y_pred_eval))\n",
        "    print(classification_report(y_eval, y_pred_eval, digits=3))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EediEwk_q-5H"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report, precision_score, recall_score, f1_score\n",
        "\n",
        "def evaluate_on_final_dataset(results_list, X_eval_scaled, y_eval):\n",
        "    \"\"\"\n",
        "    Evaluates all trained models (already tuned) on the final evaluation dataset.\n",
        "    Uses the stored best threshold per model.\n",
        "    \"\"\"\n",
        "    final_eval_results = []\n",
        "\n",
        "    print(\"Evaluating all the tuned models on the Final Evaluation Dataset (2022-2023)\")\n",
        "\n",
        "    for res in results_list:\n",
        "        model = res[\"model\"]\n",
        "        threshold = res[\"best_threshold\"]\n",
        "        name = res[\"model_name\"]\n",
        "\n",
        "        print(f\"\\n {name} - Final Evaluation\")\n",
        "\n",
        "        # Predict probabilities (if supported)\n",
        "        if hasattr(model, \"predict_proba\"):\n",
        "            y_prob_eval = model.predict_proba(X_eval_scaled)[:, 1]\n",
        "            y_pred_eval = (y_prob_eval >= threshold).astype(int)\n",
        "        elif hasattr(model, \"decision_function\"):\n",
        "            y_scores = model.decision_function(X_eval_scaled)\n",
        "            y_prob_eval = 1 / (1 + np.exp(-y_scores))\n",
        "            y_pred_eval = (y_prob_eval >= threshold).astype(int)\n",
        "        else:\n",
        "            y_pred_eval = model.predict(X_eval_scaled)\n",
        "\n",
        "        # Metrics\n",
        "        prec = precision_score(y_eval, y_pred_eval)\n",
        "        rec = recall_score(y_eval, y_pred_eval)\n",
        "        f1 = f1_score(y_eval, y_pred_eval)\n",
        "\n",
        "        print(confusion_matrix(y_eval, y_pred_eval))\n",
        "        print(classification_report(y_eval, y_pred_eval, digits=3))\n",
        "\n",
        "        final_eval_results.append({\n",
        "            \"model_name\": name,\n",
        "            \"eval_precision\": prec,\n",
        "            \"eval_recall\": rec,\n",
        "            \"eval_f1\": f1\n",
        "        })\n",
        "\n",
        "    return pd.DataFrame(final_eval_results)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yWKm-QfWq-5H"
      },
      "outputs": [],
      "source": [
        "# Evaluating all tuned models on the final evaluation dataset\n",
        "final_eval_df = evaluate_on_final_dataset(results, X_final_eval_scaled, y_final_eval)\n",
        "print(\"\\n Final Evaluation Results (2022 dataset):\")\n",
        "print(final_eval_df.sort_values(by=\"eval_f1\", ascending=False).to_string(index=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "id": "-r5ePjfhq-5H"
      },
      "source": [
        "# Visualisations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CLFh1vZKq-5H"
      },
      "outputs": [],
      "source": [
        "#Distribution of flows during on peak hours\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.hist(tds_onpeak['SPEED_MS_AVG']*3.6, bins=40, color='skyblue', edgecolor='black', alpha=0.7)\n",
        "\n",
        "plt.axvline(ffs_kmh_2, color='red', linestyle='--', linewidth=2, label=f'85th percentile (FFS = {ffs_kmh_2:.2f} km/h)')\n",
        "plt.axvline(cong_th_2, color='green', linestyle='--', linewidth=2, label=f'Congestion threshold (70% of FFS = {cong_th_2:.2f} km/h)')\n",
        "plt.xlabel('Speed (km/h)') # Corrected xlabel\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.title(\"Distribution of Speed During On-Peak (07:30â€“08:30)\") # Corrected title\n",
        "# plt.legend() # Removed legend call as no labels are defined\n",
        "plt.grid(alpha=0.3)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZVgK5W8rq-5H"
      },
      "outputs": [],
      "source": [
        "#dist of speeds during off peak hours.\n",
        "\n",
        "# Plot histogram\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.hist(tds_offpeak['SPEED_MS_AVG']*3.6, bins=40, color='skyblue', edgecolor='black', alpha=0.7)\n",
        "plt.axvline(ffs_kmh, color='red', linestyle='--', linewidth=2, label=f'85th percentile (FFS = {ffs_kmh:.2f} km/h)')\n",
        "plt.axvline(cong_th, color='green', linestyle='--', linewidth=2, label=f'Congestion threshold (70% of FFS = {cong_th_2:.2f} km/h)')\n",
        "\n",
        "\n",
        "\n",
        "plt.xlabel(\"Speed (km/h)\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.title(\"Distribution of Speeds During Off-Peak (04:00â€“06:00)\")\n",
        "plt.legend()\n",
        "plt.grid(alpha=0.3)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "itn2Jr9Lq-5H"
      },
      "outputs": [],
      "source": [
        "#plot of relation between speed and flow\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.scatterplot(data=tds_onpeak, x=\"FLOW\", y=\"SPEED_MS_AVG\", alpha=0.4, color=\"teal\")\n",
        "plt.title(\"Speedâ€“Flow Relationship\")\n",
        "plt.xlabel(\"Flow (veh/min)\")\n",
        "plt.ylabel(\"Speed (m/s)\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Byqwitfq-5I"
      },
      "outputs": [],
      "source": [
        "#correlation heatmap of features\n",
        "plt.figure(figsize=(10, 8))\n",
        "corr = tds_fixad.corr(numeric_only=True)\n",
        "sns.heatmap(corr, cmap='coolwarm', center=0, annot=False)\n",
        "plt.title(\"Correlation Heatmap of Engineered Features\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wJT9a0Wfq-5I"
      },
      "outputs": [],
      "source": [
        "tds_noNAN[\"hour\"] = tds_noNAN[\"datetime\"].dt.hour\n",
        "hourly_stats = tds_noNAN.groupby(\"hour\")[[\"SPEED_MS_AVG\", \"FLOW\"]].mean().reset_index()\n",
        "\n",
        "fig, ax1 = plt.subplots(figsize=(8, 5))\n",
        "ax2 = ax1.twinx()\n",
        "ax1.plot(hourly_stats[\"hour\"], hourly_stats[\"SPEED_MS_AVG\"], color='tab:blue', label='Speed (m/s)')\n",
        "ax2.plot(hourly_stats[\"hour\"], hourly_stats[\"FLOW\"], color='tab:orange', label='Flow (veh/min)')\n",
        "ax1.set_xlabel(\"Hour of Day\")\n",
        "ax1.set_ylabel(\"Speed (m/s)\", color='tab:blue')\n",
        "ax2.set_ylabel(\"Flow (veh/min)\", color='tab:orange')\n",
        "plt.title(\"Average Hourly Variation in Speed and Flow\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dA8U0q24q-5I"
      },
      "outputs": [],
      "source": [
        "# re-running PCA on training sclaed features.\n",
        "pca = PCA()\n",
        "pca.fit(X_train_scaled)\n",
        "\n",
        "# cumulative explained variance\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(\n",
        "    np.cumsum(pca.explained_variance_ratio_),\n",
        "    marker='o', linewidth=2, color='teal'\n",
        ")\n",
        "plt.title('PCA Explained Variance Ratio', fontsize=14)\n",
        "plt.xlabel('Number of Components')\n",
        "plt.ylabel('Cumulative Explained Variance')\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Save"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "xrrMgzygaK7k",
        "7RsN-zqHaNuX",
        "IWZZTtL3bl6K",
        "3DSsQmmiaYw9",
        "sGFQ4cUoaadw",
        "1xYNAEVgb2lL",
        "yoBXgQo-hG_U"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}